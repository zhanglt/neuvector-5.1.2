1.1.1 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 /etc/kubernetes/manifests/kube-apiserver.yaml
1.1.2 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root /etc/kubernetes/manifests/kube-apiserver.yaml
1.1.3 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 /etc/kubernetes/manifests/kube-controller-manager.yaml
1.1.4 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root /etc/kubernetes/manifests/kube-controller-manager.yaml
1.1.5 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 /etc/kubernetes/manifests/kube-scheduler.yaml
1.1.6 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root /etc/kubernetes/manifests/kube-scheduler.yaml
1.1.7 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 /etc/kubernetes/manifests/etcd.yaml
1.1.8 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root /etc/kubernetes/manifests/etcd.yaml
1.1.9 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 <path/to/cni/files>
1.1.10 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root <path/to/cni/files>
1.1.11 :  On the etcd server node, get the etcd data directory, passed as an argument --datadir,from the below command: ps -ef | grep etcd Run the below command (based on the etcd data directory found above). For example, chown etcd:etcd /var/lib/etcd
1.1.12 :  On the etcd server node, get the etcd data directory, passed as an argument --data-dir, from the below command: ps -ef | grep etcd Run the below command (based on the etcd data directory found above). For example, chown etcd:etcd /var/lib/etcd
1.1.13 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 /etc/kubernetes/admin.conf
1.1.14 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root /etc/kubernetes/admin.conf
1.1.15 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 /etc/kubernetes/scheduler.conf
1.1.16 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root /etc/kubernetes/scheduler.conf
1.1.17 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 /etc/kubernetes/controller-manager.conf
1.1.18 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root /etc/kubernetes/controller-manager.conf
1.1.19 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chown -R root:root /etc/kubernetes/pki/
1.1.20 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod -R 600 /etc/kubernetes/pki/*.crt
1.1.21 :  Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod -R 600 /etc/kubernetes/pki/*.key
1.2.1 :  Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the below parameter. --anonymous-auth=false
1.2.2 :  Follow the documentation and configure alternate mechanisms for authentication. Then,edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the master node and remove the --token-auth-file=<filename> parameter.
1.2.3 :  Edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the master node and remove the `--DenyServiceExternalIPs'parameter or The Kubernetes API server flag disable-admission-plugins takes a comma-delimited list of admission control plugins to be disabled, even if they are in the list of plugins enabled by default.kube-apiserver --disable-admission-plugins=DenyServiceExternalIPs,AlwaysDeny...
1.2.4 :  Follow the Kubernetes documentation and set up the TLS connection between the apiserver and kubelets. Then, edit API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the kubelet client certificate and key parameters as below. --kubelet-client-certificate=<path/to/client-certificate-file> --kubelet-client-key=<path/to/client-key-file>
1.2.5 :  Follow the Kubernetes documentation and setup the TLS connection between the apiserver and kubelets. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the -- kubelet-certificate-authority parameter to the path to the cert file for the certificate authority. --kubelet-certificate-authority=<ca-string>
1.2.6 :  Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the --authorization-mode parameter to values other than AlwaysAllow . One such example could be as below. --authorization-mode=RBAC
1.2.7 :  Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the --authorization-mode parameter to a value that includes Node . --authorization-mode=Node,RBAC
1.2.8 :  Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the --authorization-mode parameter to a value that includes RBAC, for example:--authorization-mode=Node,RBAC
1.2.9 :  Follow the Kubernetes documentation and set the desired limits in a configuration file.Then, edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml and set the below parameters.--enable-admission-plugins=...,EventRateLimit,...--admission-control-config-file=<path/to/configuration/file>
1.2.10:  Edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and either remove the --enable-admissionplugins parameter, or set it to a value that does not include AlwaysAdmit.
1.2.11:  Edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and set the --enable-admission-plugins parameter to include AlwaysPullImages.--enable-admission-plugins=...,AlwaysPullImages,...
1.2.12:  Edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and set the --enable-admission-plugins parameter to include SecurityContextDeny, unless PodSecurityPolicy is already in place.--enable-admission-plugins=...,SecurityContextDeny,...
1.2.13:  Follow the documentation and create ServiceAccount objects as per your environment.Then, edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the master node and ensure that the --disable-admission-plugins parameter is set to a value that does not include ServiceAccount
1.2.14:  Edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and set the --disable-admission-plugins parameter to ensure it does not include NamespaceLifecycle.
1.2.15:  Follow the Kubernetes documentation and configure NodeRestriction plug-in on kubelets. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the --enable-admission-plugins parameter to a value that includes NodeRestriction.--enable-admission-plugins=...,NodeRestriction,...
1.2.16:  Edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and either remove the --secure-port parameter or set it to a different (non-zero) desired port.
1.2.17:  Edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and set the below parameter.--profiling=false
1.2.18:  Edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and set the --audit-log-path parameter to a suitable path and file where you would like audit logs to be written, for example:--audit-log-path=/var/log/apiserver/audit.log
1.2.19:  Edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and set the --audit-log-maxage parameter to 30 or as an appropriate number of days:--audit-log-maxage=30
1.2.20:  Edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and set the --audit-log-maxbackup parameter to 10 or to an appropriate value. --audit-log-maxbackup=10
1.2.21:  Edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and set the --audit-log-maxsize parameter to an appropriate size in MB. For example, to set it as 100 MB:--audit-log-maxsize=100
1.2.22:  Edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml and set the below parameter as appropriate and if needed. For example,--request-timeout=300s
1.2.23:  Edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and set the below parameter.--service-account-lookup=true Alternatively, you can delete the --service-account-lookup parameter from this file so that the default takes effect.
1.2.24:  Edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the Control Plane node and set the --service-account-key-file parameter to the public key file for service accounts:--service-account-key-file=<filename>
1.2.25:  Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the etcd certificate and key file parameters.--etcd-certfile=<path/to/client-certificate-file> --etcd-keyfile=<path/to/client-key-file>
1.2.26:  Follow the Kubernetes documentation and set up the TLS connection on the apiserver.Then, edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver.yaml on the master node and set the TLS certificate and private key file parameters.--tls-cert-file=<path/to/tls-certificate-file> --tls-private-key-file=<path/to/tls-key-file>
1.2.27:  Follow the Kubernetes documentation and set up the TLS connection on the apiserver. Then, edit the API server pod specification file /etc/kubernetes/manifests/kubeapiserver. yaml on the master node and set the client certificate authority file. --client-ca-file=<path/to/client-ca-file>
1.2.28:  Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the etcd certificate authority file parameter. --etcd-cafile=<path/to/ca-file>
1.2.29:  Follow the Kubernetes documentation and configure a EncryptionConfig file. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the --encryption-provider-config parameter to the path of that file: --encryption-provider-config=</path/to/EncryptionConfig/File>
1.2.30:  Follow the Kubernetes documentation and configure a EncryptionConfig file. In this file,choose aescbc, kms or secretbox as the encryption provider.
1.2.31:  Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the below parameter.
1.3.1 :  Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube-controller-manager.yaml on the master node and set the --terminated-pod-gc-threshold to an appropriate threshold, for example: --terminated-pod-gc-threshold=10
1.3.2 :  Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube-controller-manager.yaml on the master node and set the below parameter. --profiling=false
1.3.3 :  Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube-controller-manager.yaml on the master node to set the below parameter. --use-service-account-credentials=true
1.3.4 :  Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube-controller-manager.yaml on the master node and set the --service-account-private- key-file parameter to the private key file for service accounts. --service-account-private-key-file=<filename>
1.3.5 :  Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube-controller-manager.yaml on the master node and set the --root-ca-file parameter to the certificate bundle file`. --root-ca-file=<path/to/file>
1.3.6 :  Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube-controller-manager.yaml on the master node and set the --feature-gates parameter to include RotateKubeletServerCertificate=true. --feature-gates=RotateKubeletServerCertificate=true
1.3.7 :  Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube-controller-manager.yaml on the master node and ensure the correct value for the --bind-address parameter.
1.4.1 :  Edit the Scheduler pod specification file /etc/kubernetes/manifests/kube-scheduler.yaml file on the master node and set the below parameter. --profiling=false
1.4.2 :  Edit the Scheduler pod specification file /etc/kubernetes/manifests/kube-scheduler.yaml on the master node and ensure the correct value for the --bind-address parameter
2.1 :  Follow the etcd service documentation and configure TLS encryption. Then, edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and set the below parameters.  --cert-file=</path/to/ca-file> --key-file=</path/to/key-file>
2.2 :  Edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and set the below parameter. --client-cert-auth="true"
2.3 :  Edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and either remove the --auto-tls parameter or set it to false. --auto-tls=false
2.4 :  Follow the etcd service documentation and configure peer TLS encryption as appropriate for your etcd cluster. Then, edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and set the below parameters.  --peer-cert-file=</path/to/peer-cert-file> --peer-key-file=</path/to/peer-key-file>
2.5 :  Edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and set the below parameter. --peer-client-cert-auth=true
2.6 :  Edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and either remove the --peer-auto-tls parameter or set it to false. --peer-auto-tls=false
2.7 :  Follow the etcd documentation and create a dedicated certificate authority setup for the etcd service. Then, edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and set the below parameter. --trusted-ca-file=</path/to/ca-file>
3.1.1 :  Alternative mechanisms provided by Kubernetes such as the use of OIDC should be implemented in place of client certificates.
3.1.2 : Alternative mechanisms provided by Kubernetes such as the use of OIDC should be implemented in place of service account tokens.
3.1.3 :Alternative mechanisms provided by Kubernetes such as the use of OIDC should be implemented in place of bootstrap tokens.
3.2.1 :  Create an audit policy file for your cluster.
3.2.2 :  Consider modification of the audit policy in use on the cluster to include these items, at a minimum.
4.1.1 :  Run the below command (based on the file location on your system) on the each worker node. For example, chmod 600 /etc/systemd/system/kubelet.service.d/kubeadm.conf
4.1.2 :  Run the below command (based on the file location on your system) on the each worker node. For example, chown root:root /etc/systemd/system/kubelet.service.d/kubeadm.conf
4.1.3 :  Run the below command (based on the file location on your system) on the each worker node. For example, chmod 600 <proxy kubeconfig file>
4.1.4 :  Run the below command (based on the file location on your system) on the each worker node. For example, chown root:root <proxy kubeconfig file>
4.1.5 :  Run the below command (based on the file location on your system) on the each worker node. For example, chmod 600 /etc/kubernetes/kubelet.conf
4.1.6 :  Run the below command (based on the file location on your system) on the each worker node. For example, chown root:root /etc/kubernetes/kubelet.conf
4.1.7 :  Run the following command to modify the file permissions of the --client-ca-file chmod 600 <filename>
4.1.8 :  Run the following command to modify the ownership of the --client-ca-file. chown root:root <filename>
4.1.9 :  Run the following command (using the config file location identied in the Audit step) chmod 600 /var/lib/kubelet/config.yaml
4.1.10 :  Run the following command (using the config file location identied in the Audit step) chown root:root /etc/kubernetes/kubelet.conf
4.2.1 :  If using a Kubelet config file, edit the file to set authentication: anonymous: enabled to false. If using executable arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable. --anonymous-auth=false Based on your system, restart the kubelet service. For example:  systemctl daemon-reload systemctl restart kubelet.service
4.2.2 :  If using a Kubelet config file, edit the file to set authorization: mode to Webhook. If using executable arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_AUTHZ_ARGS variable. --authorization-mode=Webhook Based on your system, restart the kubelet service. For example:  systemctl daemon-reload systemctl restart kubelet.service
4.2.3 :  If using a Kubelet config file, edit the file to set authentication: x509: clientCAFile to the location of the client CA file. If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_AUTHZ_ARGS variable. --client-ca-file=<path/to/client-ca-file> Based on your system, restart the kubelet service. For example:  systemctl daemon-reload systemctl restart kubelet.service
4.2.4 :  If using a Kubelet config file, edit the file to set readOnlyPort to 0. If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable. --read-only-port=0 Based on your system, restart the kubelet service. For example:  systemctl daemon-reload systemctl restart kubelet.service
4.2.5 :  If using a Kubelet config file, edit the file to set streamingConnectionIdleTimeout to a value other than 0. If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable. --streaming-connection-idle-timeout=5m Based on your system, restart the kubelet service. For example:  systemctl daemon-reload systemctl restart kubelet.service
4.2.6 :  If using a Kubelet config file, edit the file to set protectKernelDefaults: true. If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable. --protect-kernel-defaults=true Based on your system, restart the kubelet service. For example:  systemctl daemon-reload systemctl restart kubelet.service
4.2.7 :  If using a Kubelet config file, edit the file to set makeIPTablesUtilChains: true. If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and remove the --make-iptables-util-chains argument from the KUBELET_SYSTEM_PODS_ARGS variable. Based on your system, restart the kubelet service. For example:  systemctl daemon-reload systemctl restart kubelet.service
4.2.8 :  Edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and remove the --hostname-override argument from the KUBELET_SYSTEM_PODS_ARGS variable. Based on your system, restart the kubelet service. For example:  systemctl daemon-reload systemctl restart kubelet.service
4.2.9 :  If using a Kubelet config file, edit the file to set eventRecordQPS: to an appropriate level. If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable. Based on your system, restart the kubelet service. For example:  systemctl daemon-reload systemctl restart kubelet.service
4.2.10 :  If using a Kubelet config file, edit the file to set tlsCertFile to the location of the certificate file to use to identify this Kubelet, and tlsPrivateKeyFile to the location of the corresponding private key file. If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameters in KUBELET_CERTIFICATE_ARGS variable.  --tls-cert-file=<path/to/tls-certificate-file> --tls-private-key- file=<path/to/tls-key-file> Based on your system, restart the kubelet service. For example:  systemctl daemon-reload systemctl restart kubelet.service
4.2.11 :  If using a Kubelet config file, edit the file to add the line rotateCertificates: true or remove it altogether to use the default value. If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and remove --rotate-certificates=false argument from the KUBELET_CERTIFICATE_ARGS variable. Based on your system, restart the kubelet service. For example: systemctl daemon-reload systemctl restart kubelet.service
4.2.12 :  On the master edit /var/lib/kubelet/kubeadm-flags.env and set the parameter KUBELET_CERTIFICATE_ARGS --feature-gates=RotateKubeletServerCertificate=true or as an alternative, and suggested as a last resort, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_CERTIFICATE_ARGS variable. --feature-gates=RotateKubeletServerCertificate=true Based on your system, restart the kubelet service. For example:  systemctl daemon-reload systemctl restart kubelet.service
4.2.13 :  Decide on an appropriate level for this parameter and set it, either via the --pod-maxpids command line parameter or the PodPidsLimit configuration file setting.
5.1.1 :  Identify all clusterrolebindings to the cluster-admin role. Check if they are used and if they need this role or if they could use a role with fewer privileges. Where possible, first bind users to a lower privileged role and then remove the clusterrolebinding to the cluster-admin role : kubectl delete clusterrolebinding [name]
5.1.2 :  Where possible, remove get, list and watch access to secret objects in the cluster.
5.1.3 :  Where possible replace any use of wildcards in clusterroles and roles with specific objects or actions.
5.1.4 :  Where possible, remove create access to pod objects in the cluster.
5.1.5 :  Create explicit service accounts wherever a Kubernetes workload requires specific access to the Kubernetes API server. Modify the configuration of each default service account to include this value automountServiceAccountToken: false
5.1.6 :  Modify the definition of pods and service accounts which do not need to mount service account tokens to disable it.
5.1.7 :  Remove the system:masters group from all users in the cluster.
5.1.8 :  Where possible, remove the impersonate, bind and escalate rights from subjects.
5.1.9 :  Where possible, remove create access to PersistentVolume objects in the cluster.
5.1.10 :  The ability to use the proxy sub-resource of node objects opens up possibilities for privilege escalation and should be restricted, where possible.
5.1.11 :  Where possible, remove access to the approval sub-resource of certificatesigningrequest objects.
5.1.12 :  Where possible, remove access to the validatingwebhookconfigurations or mutatingwebhookconfigurations objects
5.1.13 :  Where possible, remove access to the token sub-resource of serviceaccount objects.
5.2.1 :  Ensure that either Pod Security Admission or an external policy control system is in place for every namespace which contains user workloads.
5.2.2 :  Add policies to each namespace in the cluster which has user workloads to restrict the admission of privileged containers.
5.2.3 :  Add policies to each namespace in the cluster which has user workloads to restrict the admission of hostPID containers.
5.2.4 :  Add policies to each namespace in the cluster which has user workloads to restrict the admission of hostIPC containers.
5.2.5 :  Add policies to each namespace in the cluster which has user workloads to restrict the admission of hostNetwork container
5.2.6 :  Add policies to each namespace in the cluster which has user workloads to restrict the admission of conatiners with .spec.allowPrivilegeEscalationset to true.
5.2.7 :  Create a policy for each namespace in the cluster, ensuring that either MustRunAsNonRoot or MustRunAs with the range of UIDs not including 0, is set.
5.2.8 :  Add policies to each namespace in the cluster which has user workloads to restrict the admission of containers with the NET_RAW capability.
5.2.9 :  Ensure that allowedCapabilities is not present in policies for the cluster unless it is set to an empty array.
5.2.10 :  Review the use of capabilities in applications running on your cluster. Where a namespace contains applications which do not require any Linux capabilities to operate consider adding a policy which forbids the admission of containers which do not drop all capabilities.
5.2.11 : Add policies to each namespace in the cluster which has user workloads to restrict the admission of hostProcess containers.
5.2.12 : Add policies to each namespace in the cluster which has user workloads to restrict the admission of containers which use hostPath volumes.
5.2.13 : Add policies to each namespace in the cluster which has user workloads to restrict the admission of containers which use hostPort sections.
5.3.1 :  If the CNI plugin in use does not support network policies, consideration should be given to making use of a different plugin, or finding an alternate mechanism for restricting traffic in the Kubernetes cluster.
5.3.2 :  Follow the documentation and create NetworkPolicy objects as you need them.
5.4.1 :  If possible, rewrite application code to read secrets from mounted secret files, rather than from environment variables.
5.4.2 :  Refer to the secrets management options offered by your cloud provider or a third-party secrets management solution.
5.5.1 :  Follow the Kubernetes documentation and setup image provenance.
5.7.1 :  Follow the documentation and create namespaces for objects in your deployment as you need them.
5.7.2 :  Use security context to enable the docker/default seccomp profile in your pod definitions. An example is as below:securityContext:seccompProfile:type: RuntimeDefault
5.7.3 :  Follow the Kubernetes documentation and apply security contexts to your pods. For a suggested list of security contexts, you may refer to the CIS Security Benchmark for Docker Containers.
5.7.4 :  Ensure that namespaces are created to allow for appropriate segregation of Kubernetes resources and that all new resources are created in a specific namespace.
